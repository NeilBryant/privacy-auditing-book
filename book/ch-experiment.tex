\chapter{Designing experiments for privacy auditing}

In everyday speech people frequently use the word ``experiment'' to
mean that they are going to ``try something new.'' For example, a
person might conduct an ``experiment'' in the kitchen by adding more
salt and pepper to the fish---more salt might be a good thing, but too
much salt might make the dish inedible.  Experiments such as these are
hard to carry out systematically, though, because two many factors are
changed at once. The flavor of the dish might be subtly influenced by
the specific fish---where it lived or its age, for example. The flavor
might also depend on the what the taster ate earlier in the
day. Experimental results can also be influenced by expectation---if
we know that we put more salt in the dish, we might expect it to taste
saltier and judge the dish accordingly. So while experimenting in the
kitchen by adding a bit more salt to the fish might be informative,
considerably more effort is required if we want to discover something
that can be generalized to other circumstances. To do that we need to
use the scientific method.

Scientific experiments involve more than simply trying something new
to see what happens. Whereas in the kitchen we might start out with
the question ``what can I do with the ingredients that I've got?'',
scientific experiments are designed to learn or confirm a specific
facts. To do this experiments typically combine some kind of
\emph{test} or \emph{intervention} with one or more
\emph{measurements} or \emph{observations}. Experiments should be
repeated to account for minor variations or errors, and they should be
described in sufficient detail so that they can be repeated by
others.

\section{The Experimental Steps: A Worked Example}

Experimentation is one of the core technique that we use in technical privacy
auditing to understand how systems retain or transmit personal
information. In most cases these experiments will be quite
straightforward: 

\begin{itemize}
\item We will use a digital system.
\item We will analyze the system with digital forensics tools to see
  what kind of personal information is retained or transmitted.
\end{itemize}

Things are rarely so simple, of course. Digital computers are
complex systems. Finding information on a system doesn't mean that we
put it there---the information might have been there from the
beginning. Likewise, \emph{not finding} information is no guarantee
that the information is not present. The information may be present
but the tool is unable to extract it; the operator may use the tool
improperly; or the tool may extract the information but in a form that
the operator does not recognize.

In practice, technical privacy auditing requires more than running a single
experiment. We'll need multiple experiments aimed at uncovering a wide
range of digital phenomena. We'll need to test the digital system
to see how it operates normally. We'll need to test our tools to see
if they can recover the specific kind information for which we are
looking.

\subsection{Private Browsing Mode}

To make this example more concrete, let's consider a researcher who
wants to test the ``private browser mode'' on web browser to see if
the browser retains information that it should not.

The concept of a privacy mode for web browsing was introduced by the
Apple's Safari in Mac OS X v10.4 Tiger in 2005. At the time there was
a growing realization among computer users that web browsers
retained many kinds of information about websites that were
visited, and that this information could be damaging to a person's
privacy in the case of a shared computer. Although web browsers had
the ability to ``clear history,'' ``clear cookies'' and ``empty the cache,'' these are
typically drastic actions that remove useful information or important
as well. What's more, they leave evidence that something has been
deleted. Apple's ``private browsing'' mode instead let users simply
tell Safari to stop recording what the user was doing.

The idea of private gained popularity and was implemented in all of
the major browsers within a few
years. \citeN{Aggarwal:2010:APB:1929820.1929828} analyzed the private
browsing models of several popular browsers and found that they all
implemented the feature differently and retained different kinds of
information during private browsing. This isn't entirely surprising,
of course, since there are many ways that a website can leave
identifying information on a user's computer, there was no generally
accepted specification as to what private browsing should do, and
there was no way to consistently test a browser to see if it was in
compliance with the user's expectations.

As first blush, testing the private browsing mode of a browser seems
pretty straightforward:

\begin{itemize}
\item Turn on private browsing.
\item Browse some websites.
\item Analyze the browser and see if any evidence of the websites was
  left behind. 
\end{itemize}

This simple methodology has an important problem. Without testing and
experimentation, we have no way of knowing if our tools can find the
kind of information left behind during the course of normal
browsing. As a result, if we don't find information, we don't know if
the emptiness is the result of a properly implemented private browsing
mode or the result of tool failure.

A second problem with this methodology is that it doesn't give us
enough information for explaining the information we do find. That is,
there's no way to know if the information found is the result of our
browsing activities or something else.

\subsection{Experiment \#1: Understanding Normal Behavior}

Before we can evaluate the private browsing mode, we need to be able
to characterize the browser's normal behavior. Specifically we need to
verify that we can reliably information that we place on the computer
during normal browsing.

We might do so with this sequence of steps:

\begin{itemize}
\item Be sure that private browsing is turned off.
\item Browse some websites.
\item Analyze the browser with the DF tool to see if any evidence that the websites
  were visited was left behind. 
\end{itemize}

This is better: if we find evidence with the DF tool we know that it
can extract the kind of evidence that we are looking for. But there
is still an important problem: we don't know if the data was placed there
as a result of our browsing.

\subsubsection{Documenting the Initial State}
In order to know that our browsing was responsible for the evidence
that was recovered, we need to verify that the evidence was not
present \emph{before} we performed our browsing. To do that we need to
document the system's initial state before our experiment
begins. Instead of analyzing the system once, we'll analyze it
twice---before and after the intervention---and compare the
results. Anything that's changed should be the result of our activity.

We now have this sequence of steps:


\begin{itemize}
\item Be sure that private browsing is turned off.
\item Using the DF tool, capture the system's state and store it in dataset $D_0$.
\item Browse some websites.
\item Capture the system's state a second time and store the results in dataset $D_1$.
\item Compare the datasets $D_0$ and $D_1$ to determine what's
  changed. Analyze this changed data to see if they contain any
  evidence of the browsed websites. 
\end{itemize}

\subsubsection{Clearing the system}

It is easier to analyze systems that are simple. In this case, we can
simplify the system by clearing the system before begin our
experiment. That adds two more steps to our procedure:

\begin{itemize}
\item Wipe the computer's hard drive.
\item Install the operating system and a web browser.
\item Be sure that private browsing is turned off.
\item Using the DF tool, capture the system's state and store it in dataset $D_0$.
\item Browse some websites.
\item Capture the system's state a second time and store the results in dataset $D_1$.
\item Compare the datasets $D_0$ and $D_1$ to determine what's
  changed. Analyze this changed data to see if they contain any
  evidence of the browsed websites. 
\end{itemize}


\subsubsection{Self-Identifying Data}





---it requires a series of experiments 



So in practice we might want a more complex procedure:

\begin{itemize}
\item We will analyze the system with our tools to find out what
  information is present. We will call this dataset $D_1$. 
\item We will use a digital system.
\item We will analyze the system a second time with our tools,
  producing dataset $D_2$. 
\item We will compare $D_2$ with $D_1$ and determine what changed. In
  particular, we will look to see if privacy-sensitive information was
  present in $D_2$ that was not present in $D_1$. 
\end{itemize}



and
the tools that we use to analyze them are complex systems. In practice
we need to understand both systems are
complex systems. , and digital forensic tools rarely provide the
exact answers for which their users are looking. kind of information that we're looking for. 

in
digital systems. But experimentation plays many other roles as well:

TK

\begin{itemize}
\item We test digital forensics tools to see what kind of information they can recover.
\item We test the information that is recovered to see if it
  accurately reflects the information that was originally present.
\item We test computer systems to see what kinds of information they have.
\item We test software that runs on computer systems to see what kinds
  of information it may create, destroy, or leave behind.
\end{itemize}

As with cooking, digital forensics experiments can result in epistemological
confusion---we might think that the experiment means one thing when in
fact it means something else. If a tool finds a piece of data on a piece of media, was
the data present or did the tool manufacturer the data? If a tool
fails to find data on media, is the data really not present, or does
the tool have a bug?

There are many ways to reduce the confusion. For example, we can use
tools that have been
tested and validated by a third party.\footnote{The \emph{first party}
  is the tool provider and the \emph{second party} is the tool user,
  so another organization that is testing the tool is said to be a
  \emph{third party}.} The Computer Forensics Tool
Testing Program at the National Institute of
Standards and Technology tests disk imaging tools to make sure that
the tools accurately copy data from a hard drive to a disk image
file. To test the tools, a technician will copy known data onto a hard
drive and then use the tool under test to copy the data off. The copied data
should match the original.

Here's where things get complicated. If the data match, the tool is
not necessarily flawless. And if the data doesn't match, the tool
is not necessarily flawed? The two data sets may match by chance even
if the tool is flawed, and if the data sets may be different for
reasons that have nothing to do with the tool---for example, the drive
may have a bad sector. 

One of the difficult things about digital forensics is that we
can never really trust our tools and what we think they are telling
us. We resolve this issue by designing our experiments with internal
checks and controls. Such measures provide assurance that is mutually reinforcing.

\section{Designing An Experiment}


\subsection{Purpose of your experiment}

Many people start designing an experiment by thinking about what they
are going to do---what materials they are going to work with, what they are going to
change, and what data they are going to collect. This is almost always
the wrong way to design an experiment.

\subsection{Experimental Complexity}

\subsection{Controls}

\subsection{Variables}

\section{Why experiment?}

why should you experiment?

\section{What is the purpose of the experiment? - what you can provide and what you can't}
\section{Start with a wipe}
\section{Use Self-Identifying Data}

What self-identifing data is.


% M-sequences in radar
% KW37 - keying is for a day; you can join anytime.
% Watermarking - covert and robust go together
% hackmem search algorithm

\section{Sampling vs. Complete Analysis}

sometimes you can analyze all the data, but frequently you can't

\section{Working with large amounts of data}
 - What's large?
 - 4GiB limitations (FAT32, ZIP vs. ZIP64)
\section{Error Rates}
\subsection{What is an error rate}
\subsection{Error rates from hardware}
\subsection{Error rates from sampling}

